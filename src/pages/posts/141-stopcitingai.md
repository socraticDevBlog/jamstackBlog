---
title: "cessons de déléguer notre intelligence à un llm"
date: 2025-11-16
author: "SocraticDev"
image: ../../images/stop_citing_ai.png
tags:
  - ai
  - fun
  - croissance
is_archived: true
---

C'est le message que veut passer Leo Herzog, un spécialiste en IT oeuvrant au
sein d'un collège américain dans l'état du Michigan. Son petit site web nous
rend nostalgiques des app web sarcastiques comme
[lmgtfy](https://googlethatforyou.com/) ou [no hello](https://nohello.net/fr/)
qui sont utilisés pour gentiment informer ceux qui commettent des faux pas liés
à l'informatique des raisons pour lesquelles leur comportement est dérangeant
et comment s'améliorer pour réduire la friction dans leurs communications avec nous.

Le site "Stop Citing AI" récemment mis en ligne par Leo Herzog répond au même
type d'irritation causé par des utilisateurs naïfs de nouvelles technologies.
Le site "Let me Google that for you" (lmgtfy) apprenait aux néophytes à
utiliser un moteur de recherche pour répondre à leurs questions avant de
déranger un ami ou un collègue de travail pour leur poser une question à laquelle Google peut facilement répondre. Même chose pour "No Hello" qui
apprend aux gens peu habitués à l'utilisation d'outils de communication
asynchrone comme Microsoft Teams ou Slack qu'il ne faut pas simplement
interpeler un collègue avec un "hello" et ensuite attendre que ce dernier nous
réponde ; mais plutôt écrire d'emblée un message détaillant la demande et
laisser le récepteur de la communication répondre quand il sera disponible.

> "Ne copiez-collez pas le texte d'un chatbot pour l'envoyer à quelqu'un
> comme si sa réponse faisait autorité."

"Stop Citing AI" franchit un pas et approche le domaine de la théorie de
l'argumentation et de l'épistémologie. Depuis la démocratisation des Large
Language Models et des outils interactifs comme ChatGPT et Claude nous avons
tous remarqué l'arrivée insidieuse d'une forme agaçante de paresse
intellectuelle. Un interlocuteur réagissant à un différend d'opinion se rabat
sur un LLM pour obtenir une réponse qui supporte sa position. Et ensuite envoi
cette réponse à son interlocuteur, comme si c'était un argument implacable.

Le site web de Leo Herzog explique, en simplifiant bien sûr, le fonctionnement
d'un LLM : produire une réponse sensée en s'appuyant sur des statistiques lui
permettant de préduire le mot suivant.

### appauvrissement de la pratique de la discussion critique

La démocratisation de l'intelligence artificielle semble avoir amplifié notre
tendance naturelle à "vouloir avoir raison" plutôt que d'utiliser notre
rationalité pour résoudre des problèmes et des différends d'opinion de façon
optimale.

Et "Stop Citing AI" c'est d'abord une claque qu'on s'inflige pour se réveiller
soi-même. Nos premiers mois avec ChatGPT a souvent été très agréable pour notre
ego ; obtenir des réponses qui confirme nos opinions et croyances c'est du feu
! Aujourd'hui, on se rend compte qu'à peu près tout le monde ayant des
croyances et opinions totalement contraire aux nôtres se voir conforter dans
leurs positions. Surtout, en apprenant comment les modèles LLM sont produits et
comment ils fonctionnent, nous nous imposons un petit _reality check_ et
prenons les réponses de LLMs avec moins de sérieux.

Vais-je maintenant envoyer l'URL "https://stopcitingai.com" à un interlocuteur
cherchant à démontrer que j'ai tort à partir d'une réponse de ChatGPT ?

Non.

Premièrement parce que c'est sarcastique et n'aidera probablement pas à
dénouer notre différence d'opinion. Deuxièmement, parce que ça se révèlerait
une encore plus grande paresse intellectuelle et ne se solderait probablement que par
l'arrêt de la discussion.

Dans un contexte d'argumentation saine plusieurs facteurs doivent être réunis.
Les deux partis doivent foncièrement souhaiter résoudre leur différend de façon
optimale pour chacun. Ils doivent d'abord reconnaître que leur relation est plus
importante que leur désaccord. L'aspect agonal où il n'y aurait qu'un vainqueur
et un vaincu ("zero-sum game") doit tout à fait être évité.

Je recommenderais d'abord d'évaluer si le jeu en vaut la
chandelle. Si ce n'est pas le cas et que votre interlocuteur fait preuve de
paresse intellectuelle en utilisant ChatGPT pour soutenir sa
position, alors ne vous engagez pas dans la discussion.

Sinon, il faut garder la tête froide et reconnaître qu'un simple copier-coller
d'une réponse de ChatGPT ne peut en aucun cas être conçu comme un argument.
L'effort mental requis pour lire et comprendre une citation d'AI par rapport à
l'effort que ca a pris à votre interlocuteur pour la générer est incomparable ;
ne laissez pas votre interlocuteur agir d'une façon odieusement inéquitable.

Ralentir l'échange et l'amener à reprendre sa part de responsabilité dans le débat me
semble être la stratégie à adopter : "Peux-tu résumer dans tes propres mots ce
que tu viens de coller ici?".

L'étude de la théorie d'argumentation nous apprend un leçon importante : la
meilleure option c'est d'éviter de mener des débats argumentatifs avec
n'importe qui et au sujet de n'importe quoi.

Il faut d'abord que ça soit un enjeu qui mérite d'être débattu.

Au final, si un interlocuteur fait preuve de paresse en vous servant un
copier-coller produit par ChatGPT, il y a fort à parier que le jeu n'en vaut
pas la chandelle.

### sources

[You’ve been sent here because you cited AI as a source to try to prove something.](https://stopcitingai.com/)
